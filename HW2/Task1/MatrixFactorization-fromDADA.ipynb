{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import Counter\n",
    "import random\n",
    "from utils import create_dataset\n",
    "from utils import load_model, save_checkpoint\n",
    "from utils import AveragePrecision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_data = pd.read_csv(\"data/rating_train.csv\")\n",
    "rating_data = rating_data.drop(['date'], axis=1).drop_duplicates()\n",
    "rating_data['label'] = 1\n",
    "user_ids = rating_data.userid.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_food_score = [{} for i in range(rating_data.userid.max()+1)]\n",
    "for u, f in zip(rating_data['userid'], rating_data['foodid']):\n",
    "    if user_food_score[u].get(f) != None:\n",
    "        user_food_score[u][f] += 1\n",
    "    else:\n",
    "        user_food_score[u][f] = 1\n",
    "    \n",
    "for i in user_ids:\n",
    "    all_val = list(user_food_score[i].values())\n",
    "    for k, v in user_food_score[i].items():\n",
    "        user_food_score[i][k] = v / max(all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_percentage = 0.5\n",
    "user_id_train, user_id_valid, food_id_train, food_id_valid, Y_train, Y_valid = create_dataset(user_food_score, rating_data, valid_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        dataset=TensorDataset(\n",
    "            torch.from_numpy(user_id_train),\n",
    "            torch.from_numpy(food_id_train),\n",
    "            torch.from_numpy(Y_train)),\n",
    "        batch_size=1024,\n",
    "        shuffle=True,\n",
    "        num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_eaten = {}\n",
    "for u in user_ids:\n",
    "    t_start_idx = np.where(user_id_train == u)[0][0]\n",
    "    t_end_idx = np.where(user_id_train == u)[0][-1]\n",
    "    v_start_idx = np.where(user_id_valid == u)[0][0]\n",
    "    v_end_idx = np.where(user_id_valid == u)[0][-1]\n",
    "    #tmp = []\n",
    "    #for i in range(v_start_idx, v_end_idx+1):\n",
    "        #if (food_id_valid[i] not in food_id_train[t_start_idx: t_end_idx+1]) and (food_id_valid[i] not in tmp):\n",
    "        #    tmp.append(food_id_valid[i])\n",
    "    #print(u)\n",
    "    #print(t_end_idx)\n",
    "    not_eaten[u] = np.setdiff1d(food_id_valid[v_start_idx: v_end_idx+1], food_id_train[t_start_idx: t_end_idx+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_foods, n_dim):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embed_layer = nn.Embedding(n_users, n_dim).cuda()\n",
    "        self.food_embed_layer = nn.Embedding(n_foods, n_dim).cuda()\n",
    "        self.user_bias_embed_layer = nn.Embedding(n_users, 1).cuda()\n",
    "        self.food_bias_embed_layer = nn.Embedding(n_foods, 1).cuda()\n",
    "        \n",
    "    def forward(self, user_train, food_train):\n",
    "        user_vec = self.user_embed_layer(user_train.cuda())\n",
    "        user_vec = nn.Dropout(0.3)(user_vec)\n",
    "        user_vec = nn.Sigmoid()(user_vec)\n",
    "        food_vec = self.food_embed_layer(food_train.cuda())\n",
    "        food_vec = nn.Dropout(0.3)(food_vec)\n",
    "        food_vec = nn.Sigmoid()(food_vec)\n",
    "        user_bias = self.user_bias_embed_layer(user_train.cuda()).view(-1)\n",
    "        food_bias = self.food_bias_embed_layer(food_train.cuda()).view(-1)\n",
    "        \n",
    "        lamb = 0.01\n",
    "        reg1 = lamb * torch.norm(torch.cat([x.view(-1) for x in self.parameters()]), 1)\n",
    "        reg2 = lamb * torch.norm(torch.cat([x.view(-1) for x in self.parameters()]), 2)\n",
    "        \n",
    "        return ((user_vec * food_vec).sum(1) + user_bias + food_bias).cuda(), reg1+reg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 10\n",
    "model = MatrixFactorization(max(user_ids)+1, rating_data.foodid.max()+1, n_dim).cuda()\n",
    "loss_func = nn.MSELoss()\n",
    "opt_u = torch.optim.Adam(list(model.user_embed_layer.parameters()), lr=0.01)\n",
    "opt_f = torch.optim.Adam(list(model.food_embed_layer.parameters()), lr=0.01)\n",
    "opt_b = torch.optim.Adam(list(model.food_bias_embed_layer.parameters())+list(model.user_bias_embed_layer.parameters()), lr=0.001)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1a5c5ec62eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregu_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mt_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3769165f5f6d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user_train, food_train)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlamb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mreg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mreg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_vec\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfood_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muser_bias\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfood_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mreg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "print_every = 1\n",
    "infer_every = 20\n",
    "best = 1e10\n",
    "best_epoch = 1\n",
    "best_map = 0\n",
    "for e in range(1, epochs+1):\n",
    "    t_loss = 0\n",
    "    for i ,(user, food, rate) in enumerate(train_loader):\n",
    "        user, food, rate = user.cuda(), food.cuda(), rate.cuda().float()\n",
    "        output, regu_loss = model(user, food)\n",
    "        loss = loss_func(output, rate)\n",
    "        t_loss += loss\n",
    "        \n",
    "    #validation\n",
    "    v_out, _ = model(user_id_valid.cuda(), food_id_valid.cuda())\n",
    "    v_loss = loss_func(v_out, Y_valid)\n",
    "    \n",
    "    opt_u.zero_grad()\n",
    "    opt_f.zero_grad()\n",
    "    opt_b.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_u.step()\n",
    "    opt_f.step()\n",
    "    opt_b.step()\n",
    "    \n",
    "    all_ap, _ = infer()\n",
    "    MAP = np.mean(all_ap)\n",
    "    if e % print_every == 0:\n",
    "        print(\"Epoch {}, train_loss = {}, valid_loss = {}, map = {}, best_map = {}\".format(e, t_loss, v_loss, MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint model.h5.best\n",
      "=> loaded checkpoint model.h5.best (epoch: 252)\n"
     ]
    }
   ],
   "source": [
    "model,_,_,_ = load_model('model.h5.best', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(): \n",
    "    F = np.arange(len(food_data), dtype=int)\n",
    "    F = [i for i in range(len(food_data))]\n",
    "    all_ans = []\n",
    "    all_score = []\n",
    "    for u in user_ids:\n",
    "        ans = []\n",
    "        U = [u for i in range(len(food_data))]\n",
    "        res = model(Variable(torch.LongTensor(U)), Variable(torch.LongTensor(F))).cpu().data.numpy()\n",
    "        res = res.flatten()\n",
    "        D = {k: v for (k, v) in zip(F, res)}\n",
    "        sorted_D = sorted(D.items(), key=lambda d: d[1], reverse=True)\n",
    "        for x in sorted_D:\n",
    "            if len(ans) >= 20: break\n",
    "            if x[0] in user_food_score[u].keys():\n",
    "                continue\n",
    "            ans.append(x[0])\n",
    "        all_score.append(AveragePrecision(not_eaten[u], ans, len(ans)))\n",
    "        all_ans.append(ans) \n",
    "    return all_score, all_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
       "       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
       "       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
       "       161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
       "       174, 175])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_eaten[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pred.csv\", 'w') as f:\n",
    "    f.write(\"userid,foodid\\n\")\n",
    "    for i in range(len(user_ids)):\n",
    "        f.write(\"{},\".format(user_ids[i]))\n",
    "        for j in all_ans[i]:\n",
    "            f.write(\"{} \".format(j))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
